{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OhE5QQ2y9WAF",
        "outputId": "2e486eca-334f-4135-e809-b1792f3a702e"
      },
      "outputs": [],
      "source": [
        "!git clone -b master https://github.com/GothiProCoder/voice-companion.git\n",
        "%cd voice-companion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p41kF_-FStXX",
        "outputId": "337b1c3d-6b91-4f4d-e4fc-9d849a6e83fc"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# PyTorch (Colab CUDA 12.1 SAFE)\n",
        "# ==============================\n",
        "!pip install --upgrade --quiet \\\n",
        "  torch torchvision torchaudio\n",
        "\n",
        "# ==============================\n",
        "# Backend + API\n",
        "# ==============================\n",
        "!pip install --quiet \\\n",
        "  fastapi \\\n",
        "  uvicorn[standard] \\\n",
        "  python-multipart \\\n",
        "  bcrypt \\\n",
        "  httpx \\\n",
        "  sseclient-py \\\n",
        "  email-validator \\\n",
        "  alembic\n",
        "\n",
        "# ==============================\n",
        "# Database\n",
        "# ==============================\n",
        "!pip install --quiet \\\n",
        "  psycopg2-binary \\\n",
        "  psycopg[binary,pool]>=3.1.0 \\\n",
        "  sqlalchemy \\\n",
        "  pgvector \\\n",
        "  langgraph-checkpoint-postgres\n",
        "\n",
        "# ==============================\n",
        "# AI / ML\n",
        "# ==============================\n",
        "!pip install --quiet \\\n",
        "  faster-whisper \\\n",
        "  sentence-transformers\n",
        "\n",
        "# ==============================\n",
        "# Audio Processing\n",
        "# ==============================\n",
        "!pip install --quiet \\\n",
        "  librosa \\\n",
        "  opensmile \\\n",
        "  soundfile \\\n",
        "  praat-parselmouth \\\n",
        "  pydub\n",
        "\n",
        "# ==============================\n",
        "# LangChain / LangGraph\n",
        "# ==============================\n",
        "!pip install --quiet \\\n",
        "  langgraph \\\n",
        "  langchain \\\n",
        "  langchain-google-genai\n",
        "\n",
        "# ==============================\n",
        "# Frontend (optional)\n",
        "# ==============================\n",
        "!pip install --quiet \\\n",
        "  streamlit \\\n",
        "  streamlit-webrtc\n",
        "\n",
        "# ==============================\n",
        "# Utilities\n",
        "# ==============================\n",
        "!pip install --quiet \\\n",
        "  python-dotenv \\\n",
        "  pydantic-settings \\\n",
        "  pytest\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR8YKhQyIsnx",
        "outputId": "31a7b6cf-192a-4967-89d3-73d275fc6bf0"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok nest-asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KwDt3DpcU2sb",
        "outputId": "0076a327-d6ac-4732-c905-9beadeac03af"
      },
      "outputs": [],
      "source": [
        "!pip uninstall transformers -y\n",
        "!pip install transformers==4.46.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IgyXARkW-JqY",
        "outputId": "dd20b84f-78f1-4d05-c629-d8691a80b784"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/parler-tts.git soundfile -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u1Fj_NGePykg",
        "outputId": "6788df9f-c11a-4d48-9569-d58e8b5631fc"
      },
      "outputs": [],
      "source": [
        "!pip install \"peft==0.17.1\" --no-cache-dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzhxrMS412_I",
        "outputId": "94a4ab68-d348-4534-cf88-c4bb946d8e18"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade CTranslate2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================ RESTART THE KERNEL ===================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB7NyvHgSmP4",
        "outputId": "15ce6b9b-36d0-402d-80b2-b3e3f3deda5a"
      },
      "outputs": [],
      "source": [
        "%cd voice-companion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "Cgfaw4jFDS89",
        "outputId": "d83db265-9ae7-4c1c-b35b-04028284ad2f"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload .env file\n",
        "uploaded = files.upload()  # Select your .env file from local machine\n",
        "\n",
        "# Load it\n",
        "!pip install python-dotenv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-3L2emLUGZI",
        "outputId": "97c50e74-0eaf-4aa0-86bf-bd7d6f334969"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv('.env')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwI5C_UuBIJY",
        "outputId": "4333b76f-76f9-4844-fae0-497d756d0ba3"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "ngrok.kill()  # Clear any old tunnels\n",
        "\n",
        "# Set up ngrok tunnel for FastAPI (port 8000)\n",
        "ngrok.set_auth_token(\"YOUR_NGROK_AUTH_TOKEN\")  # Get free token from ngrok.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olodmZnW7yiP",
        "outputId": "33c43e9d-d57c-4f2e-9003-565c343e76bf"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# COLAB ENVIRONMENT SETUP\n",
        "# ========================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "print(\"üîß Setting up Colab environment...\")\n",
        "\n",
        "# 1. Set cuDNN library path (CRITICAL for CTranslate2)\n",
        "cudnn_lib_path = \"/usr/lib/x86_64-linux-gnu\"\n",
        "if \"LD_LIBRARY_PATH\" in os.environ:\n",
        "    os.environ[\"LD_LIBRARY_PATH\"] = f\"{cudnn_lib_path}:{os.environ['LD_LIBRARY_PATH']}\"\n",
        "else:\n",
        "    os.environ[\"LD_LIBRARY_PATH\"] = cudnn_lib_path\n",
        "\n",
        "print(f\"‚úÖ LD_LIBRARY_PATH set\")\n",
        "\n",
        "# 2. Verify cuDNN files exist\n",
        "import pathlib\n",
        "cudnn_ops = pathlib.Path(\"/usr/lib/x86_64-linux-gnu/libcudnn_ops.so.9\")\n",
        "if cudnn_ops.exists():\n",
        "    print(f\"‚úÖ cuDNN ops library found: {cudnn_ops}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è cuDNN ops library NOT found at {cudnn_ops}\")\n",
        "\n",
        "# 3. Check versions\n",
        "try:\n",
        "    import ctranslate2\n",
        "    import faster_whisper\n",
        "    import torch\n",
        "\n",
        "    print(f\"‚úÖ CTranslate2: {ctranslate2.__version__}\")\n",
        "    print(f\"‚úÖ faster-whisper: {faster_whisper.__version__}\")\n",
        "    print(f\"‚úÖ PyTorch cuDNN: {torch.backends.cudnn.version()}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Version check failed: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Environment setup complete!\")\n",
        "print(\"Now you can run your initialization code...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vj16E4i-NTyy",
        "outputId": "d7b1179c-7e61-4ad5-e66a-d3e480ac376d"
      },
      "outputs": [],
      "source": [
        "# %cd voice-companion\n",
        "# Create tunnel for backend\n",
        "backend_tunnel = ngrok.connect(8000)\n",
        "backend_url = backend_tunnel.public_url\n",
        "\n",
        "print(f\"=\" * 60)\n",
        "print(f\"üöÄ BACKEND URL: {backend_url}\")\n",
        "print(f\"=\" * 60)\n",
        "print(f\"\\nüìã Copy this URL and use it on your local machine!\")\n",
        "\n",
        "# Start backend (loads models on GPU)\n",
        "print(\"\\n‚è≥ Starting backend with GPU...\")\n",
        "!uvicorn backend.main:app --host 0.0.0.0 --port 8000"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
